import { pipeline } from "@huggingface/transformers";
import { WaveFile } from "wavefile";
import fs from "fs";
import ffmpeg from "fluent-ffmpeg";
import ffmpegPath from "ffmpeg-static";
import { promisify } from "util";
import { tmpdir } from "os";
import path from "path";
import { pathToFileURL } from "url";
import { LanguageVariant } from "typescript";

ffmpeg.setFfmpegPath(ffmpegPath!);

let transcriber:any;

// ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
async function loadModel() {
  if (!transcriber) {
    transcriber = await pipeline(
      "automatic-speech-recognition",
      "Xenova/whisper-small",
        { dtype: "fp16" },
      
    );
  }
  return transcriber;
}

// ðŸ”„ ØªØ­ÙˆÙŠÙ„ Ø£ÙŠ Ù…Ù„Ù ØµÙˆØª (mp3 â†’ wav 16k mono)
async function convertToWav(inputPath:any) {
  return new Promise((resolve, reject) => {
    const outputPath = path.join(tmpdir(), `${Date.now()}.wav`);

    ffmpeg(inputPath)
      .audioChannels(1) // mono
      .audioFrequency(16000) // 16kHz
      .toFormat("wav")
      .on("end", () => resolve(outputPath))
      .on("error", reject)
      .save(outputPath);
  });
}

export async function transcribeAudio(filePath:any) {
  try {
    // Ø£ÙˆÙ„ Ø­Ø§Ø¬Ø©: Ø­ÙˆÙ‘Ù„ Ø§Ù„Ù…Ù„Ù Ù„Ùˆ wav
    const wavPath:any = await convertToWav(filePath);
    const buffer = fs.readFileSync(wavPath);

    // Ø¬Ù‡Ù‘Ø² Ù…Ù„Ù wav
    let wav = new WaveFile(buffer);
    wav.toBitDepth("32f")
    wav.toSampleRate(16000)

    let audioData = wav.getSamples();
    if (Array.isArray(audioData)) {
      if (audioData.length > 1) {
        const SCALING_FACTOR = Math.sqrt(2);
        for (let i = 0; i < audioData[0].length; ++i) {
          audioData[0][i] =
            (SCALING_FACTOR * (audioData[0][i] + audioData[1][i])) / 2;
        }
      }
      audioData = audioData[0];
    }

    const model = await loadModel();
    const output = await transcriber(audioData, {
  chunk_length_s: 30,//Ù‚Ø³Ù… Ø§Ù„ØµÙˆØª Ù„Ù…Ù‚Ø§Ø·Ø¹ 30 Ø«Ø§Ù†ÙŠØ©
  stride_length_s: 5 ,
    language: "ar",
  task: "transcribe" // ÙŠØ¹Ù…Ù„ overlap 5 Ø«ÙˆØ§Ù†ÙŠ Ø¨ÙŠÙ† Ø§Ù„Ù…Ù‚Ø§Ø·Ø¹ Ù„ØªØ¬Ù†Ø¨ Ø¶ÙŠØ§Ø¹ ÙƒÙ„Ù…Ø§Øª
});


    // Ù†Ø¸Ù‘Ù Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø¤Ù‚ØªØ©
    fs.unlinkSync(wavPath);

    return output;
  } catch (err:any) {
    console.error("Error in transcribeAudio:", err.message);
    throw err;
  }
}


















// import { pipeline } from "@huggingface/transformers";
// import { WaveFile } from "wavefile";
// import ffmpeg from "fluent-ffmpeg";
// import ffmpegPath from "ffmpeg-static";
// import fs from "fs";
// import path from "path";

// ffmpeg.setFfmpegPath(ffmpegPath!);

// let transcriber: any;
// async function loadModel() {
//   if (!transcriber) {
//     transcriber = await pipeline(
//       "automatic-speech-recognition",
//       "Xenova/whisper-medium",
//       {dtype:'fp16'}
//     );
//   }
//   return transcriber;
// }

// // Ø§Ø¬Ø¨Ø§Ø± Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ù„Ø£ÙŠ Ù…Ù„Ù (mp3 Ø£Ùˆ wav) Ù„ wav PCM 16bit
// async function ensureWavPCM(inputPath: string): Promise<string> {
//   const outputPath = path.join(
//     path.dirname(inputPath),
//     `${path.basename(inputPath, path.extname(inputPath))}_converted.wav`
//   );

//   return new Promise((resolve, reject) => {
//     ffmpeg(inputPath)
//       .outputOptions([
//         "-acodec pcm_s16le", // PCM 16-bit
//         "-ac 1",             // mono
//         "-ar 16000"          // 16 kHz
//       ])
//       .on("end", () => resolve(outputPath))
//       .on("error", reject)
//       .save(outputPath);
//   });
// }

// export async function transcribeAudio(filePath: string) {
//   try {
//     const transcriber = await loadModel();

//     // Convert input audio to wav PCM 16kHz
//     const wavFile = await ensureWavPCM(filePath);

//     // Read wav
//     const buffer = fs.readFileSync(wavFile);
//     let wav = new WaveFile(buffer);
//     wav.toBitDepth("32f");
//     wav.toSampleRate(16000);

//     let audioData: any = wav.getSamples();
//     if (Array.isArray(audioData)) {
//       audioData = audioData[0]; // mono
//     }

//     const output = await transcriber(audioData, {
//       chunk_length_s: 30,   // efficient chunking
//       stride_length_s: 5,
//       language: "en"  ,    // force Arabic
//     });

//     return output;
//   } catch (err) {
//     console.error("Error in transcribeAudio:", err);
//     throw err;
//   }
// }
